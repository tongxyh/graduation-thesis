%% 使用 njuthesis 文档类生成南京大学学位论文的示例文档
%%作者：njuhan: https://github.com/njuHan
%% 部分提纲取自njuhan的本科毕业论文

\documentclass[macfonts,phd,oneside,nobackinfo]{njuthesis}
%% njuthesis 文档类的可选参数有：
%%   nobackinfo 取消封二页导师签名信息。注意，按照南大的规定，是需要签名页的。
%%   phd/master/bachelor 选择博士/硕士/学士论文
%\let\ziju\relax
%\let\zihao\relax
%\let\songti\relax
%\let\heiti\relax
%\let\fangsong\relax
%let\kaishu\relax
%\usepackage{ctex}
\usepackage{lipsum}
\usepackage{listings} 
\usepackage{xcolor}
\lstset{breaklines}%这条命令可以让LaTeX自动将长的代码行换行排版
\lstset{extendedchars=false}%这一条命令可以解决代码跨页时，章节标题，页眉等汉字不显示的问题
\lstset{                        %Settings for listings package.
  language=[ANSI]{C},
  backgroundcolor=\color{white},
  basicstyle=\footnotesize,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  commentstyle=\color{olive},
  directivestyle=\color{blue},
  extendedchars=false,
  % frame=single,%shadowbox
  framerule=0pt,
  keywordstyle=\color{blue}\bfseries,
  morekeywords={*,define,*,include...},
  numbersep=5pt,
  rulesepcolor=\color{red!20!green!20!blue!20},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  stepnumber=2,
  stringstyle=\color{purple},
  tabsize=4,
  title=\lstname
}


\hyphenpenalty=5000
\tolerance=1000

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的中文封面

% 论文标题，不可换行
\title{智能图像编码技术}
% 论文作者姓名
\author{陈彤}
% 论文作者联系电话
\telphone{18205083599}
% 论文作者电子邮件地址
\email{tong@smail.nju.edu.cn}
% 论文作者学生证号
\studentnum{DG1923066}
% 论文作者入学年份（年级）
\grade{2019}
% 导师姓名职称
\supervisor{马展教授}
% 导师的联系电话
\supervisortelphone{}
% 论文作者的学科与专业方向
\major{信息与通信工程}
% 论文作者的研究方向
\researchfield{图像编码}
% 论文作者所在院系的中文名称
\department{电子科学与工程学院}
% 论文作者所在学校或机构的名称。此属性可选，默认值为``南京大学''。
\institute{南京大学}
% 论文的提交日期，需设置年、月、日。
\submitdate{2022年6月1日}
% 论文的答辩日期，需设置年、月、日。
\defenddate{2022年6月1日}
% 论文的定稿日期，需设置年、月、日。此属性可选，默认值为最后一次编译时的日期，精确到日。
\date{2022年6月8日}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的英文封面

% 论文的英文标题，不可换行
\englishtitle{Learned Image Compression}
% 论文作者姓名的拼音
\englishauthor{Tong Chen}
% 导师姓名职称的英文
\englishsupervisor{Professor Ma, Zhan}
% 论文作者学科与专业的英文名
\englishmajor{Information and Communication Engineering}
% 论文作者所在院系的英文名称
\englishdepartment{School of Electronic Science and Engineering}
% 论文作者所在学校或机构的英文名称。此属性可选，默认值为``Nanjing University''。
\englishinstitute{Nanjing University}
% 论文完成日期的英文形式，它将出现在英文封面下方。需设置年、月、日。日期格式使用美国的日期
% 格式，即``Month day, year''，其中``Month''为月份的英文名全称，首字母大写；``day''为
% 该月中日期的阿拉伯数字表示；``year''为年份的四位阿拉伯数字表示。此属性可选，默认值为最后
% 一次编译时的日期。
\englishdate{June 8th, 2022}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的中文摘要

% 设置中文摘要页面的论文标题及副标题的第一行。
% 此属性可选，其默认值为使用|\title|命令所设置的论文标题
% \abstracttitlea{数据中心网络模型研究}
% 设置中文摘要页面的论文标题及副标题的第二行。
% 此属性可选，其默认值为空白
% \abstracttitleb{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的英文摘要

% 设置英文摘要页面的论文标题及副标题的第一行。
% 此属性可选，其默认值为使用|\englishtitle|命令所设置的论文标题
\englishabstracttitlea{englishabstracttitlea}
% 设置英文摘要页面的论文标题及副标题的第二行。
% 此属性可选，其默认值为空白
\englishabstracttitleb{nglishabstracttitleb}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% 制作国家图书馆封面（博士学位论文才需要）
\makenlctitle
% 制作中文封面
\maketitle
% 制作英文封面
\makeenglishtitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 开始前言部分
\frontmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 论文的中文摘要
\begin{abstract}
暂无
%通过改变链路中子流的个数，分配不同的数据流量给不同的链路。

% 中文关键词。关键词之间用中文全角分号隔开，末尾无标点符号。
\keywords{关键词1 \quad 关键词2 }
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 论文的英文摘要
\begin{englishabstract}
nothing yet
%Rate adaptation can be implemented by adjusting the number of subflows on each path.

% 英文关键词。关键词之间用英文半角逗号隔开，末尾无符号。
\englishkeywords{keyword1\quad keyword2}
\end{englishabstract}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成论文目录
\tableofcontents



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 开始正文部分
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 学位论文的正文应以《绪论》作为第一章
\chapter{绪论}\label{chapter_introduction}
\section{研究背景}
%\par 分段
有损压缩图像通过社交媒体（如Facebook、微信）、照片分享（如flickr）、在线广告（如谷歌广告）等流行应用程序在互联网上广泛传播。它们大多使用一些标准的格式进行存储和传输，如JPEG~\cite{wallace1991jpeg}、JPEG2000~\cite{JPEG2K}，H.264/AVC~\cite{AVC}或更好的便携式图形的帧内编码配置文件-BPG（\url{https://bellard.org/bpg/})，遵循HEVC~\cite{HEVC}的帧内编码配置文件）。为了保持较高的图像质量（或较低的重建失真），但需要较少的比特消耗，不断需要更好的图像压缩方法。这将大大节省文件存储量。例如，从互联网规模的Facebook应用程序的角度来看，每天缓存的图片数量超过3.5亿张，每天都需要大量存储。另一方面，更好的压缩算法还可以实现更快、更高效的图像共享/交换，并具有更好的体验质量（QoE）。


\section{研究的目的与意义}
首先，进一步地提升图像编码技术的性能；针对智能图像编码技术在实用化和标准化方面依然存在的问题，进行进一步地研究和探索。




\section{论文结构}

\begin{itemize}
\item 第一章，绪论
\item 第二章，

\end{itemize}



\chapter{相关工作}
\section{传统图像和视频编码技术}
随着数字图像的出现，图像编码技术应运而生。经过了数十年的发展，已经形成了诸多广泛使用的图像编码标准。JPEG 1 标准 (ISO/IEC 10918) 创立于1992年. 它采用离散余弦变换(DCT)将数字图像信号由时域映射到频域，由于自然图像的能量集中在低频区域，因此可以通过保留更多的低频信号来压缩图片的同时，有效地保留图片信息。由于其算法简单且性能优异，直到30年后的今天，JPEG依然是最广泛使用的图像压缩标准之一。

与图像编码技术同时在飞速发展的视频编码技术，也对图像编码技术的发展带来了新鲜的血液。视频帧内编码被作为独立的模块引入到图像编码中来，相较于早期的JPEG/JPEG2000等技术，实现了明显的性能提升，因而也开始逐步成为手机移动端、数码摄影设备的主流存储格式。

\section{基于学习的智能编码技术}
深度学习技术在近十年间对计算机视觉和数字图像处理等领域产生了深远的变革。近几年来，基于深度学习技术的图像压缩算法得到了飞速的发展~\cite{balle2016end, balle2018variational, minnen2018joint}。
其中最为广泛使用的框架如图\ref{fig:vae}所示。输入图片$\bf x$经过编码器变换为特征$\bf z$，量化后的$\bf \hat{z}$经过熵编码成为最终的码流。解码器通过对应的解码器变换将熵解码后的$\bf \hat{z}$变换回原始像素空间，输出重建图像$\bf \hat{x}$。与传统图像压缩的不同之处在于，这里的编码变换、解码变换以及熵估计模块都是基于学习的网络构建并且整体通过端到端的学习来获得最优的性能。

\begin{figure}[htbp]
\centering
\includegraphics[scale=1.0]{./figs/VAE.pdf}
\caption{基于VAE的图像压缩算法框架图}
\label{fig:vae}
\end{figure}

而端到端学习的过程，码率（\textbf{R}ate）失真（\textbf{D}istortion）联合优化的过程可以以如下公式表示：
\begin{equation}
R + \lambda D = \underbrace{\mathbb{E}[-\log_2p({\bf \hat{z}})]}_{rate}+\lambda\underbrace{\mathbb{E}||{\bf x}-\hat{\bf x}||_2^2}_{distortion},
\end{equation}
其中$\lambda$用来权衡码率和失真之间的占比，计算码率所需的$p({\bf \hat{z}})$由熵估计模块提供。实际计算失真的具体方法有多种选择，这里公式中以均方差为例，也可以替换为其他的度量标准比如MS-SSIM (Multiscale Structural Similarity)~\cite{MS-SSIM}以及LPIPS (Learned Perceptual Image Patch Similarity)~\cite{zhang2018unreasonable}等。

\chapter{智能图像编码探索}



\section{基于全局注意力机制和优化的上下文建模的端到端学习图像压缩}\label{sec:rate}

\subsection{全局注意力机制}
在图像编码中，由于图像的复杂程度在不同的空间位置表现出明显的差异性，对于纹理复杂的区域给予更多的码字，而对于简单平坦的区域分配较少的码字，可以有效的提升图像压缩的性能。此种思路已经广泛应用于传统视频编码的帧内（Intra）模式中。
在基于学习的图像编码算法下，由于输入是全尺寸的图像，传统视频编码中的控制分块大小的方式不再适用。这里提出一种基于全局注意力机制的图像压缩算法。注意力机制，顾名思义，就是将时间或空间维度上的一系列信息进行了权重的分配，将更多的注意力（权重）关注在有价值的信息当中。因此将注意力机制引入到图像中来也是一种非常符合直觉的方法。注意力机制已经被广泛地应用于基于深度学习的自然语言处理（NLP）中~\cite{luong2015effective, firat2016multi, vaswani2017attention}。It can be described as a mapping strategy which queries a set of key-value pairs to an output. For low-level vision tasks [28], [18], [12], attention mechanism enables spatially adaptive feature activation with the emphasis on more challenging areas (i.e., rich textures, saliency, etc).
在图像压缩的已有工作中，注意力掩膜的想法已经被用于动态的码率分配中。比如 Li et. al	~\cite{li2017learning}通过三层局部卷积来输出掩膜，而Mentzer et. al~\cite{mentzer2018conditional}则选择将其中一个量化后的特征通道作为掩膜。 
Unfortunately, these methods require the extra explicit signaling overhead. By disabling the explicit signaling, probability estimation errors are induced. Our model adopts attention mechanism that is conceptually close to [18], [12] but applies multiscale attention masks at different layers implicitly to adaptively weigh latent features for compression.
相比于只利用了局部信息的注意力模块，全局注意力可以在整个特征空间进行注意力的计算。

如图\ref{sfig:non_local_attention} 和图\ref{sfig:non_local_fig}所示，NLAM 采用非局部网络（NLN）~\cite{wang2018non} 作为基本单元, . This NLN computes the output at $i$-th position, ${\bf V}_i$, using a weighted average of the transformed feature values of 输入$\bf U$, as below:
\begin{equation}
{\bf V}_i = \frac{1}{C({\bf U})}{\sum_{{\forall}j}}f({\bf U}_i, {\bf U}_j)g({\bf U}_j),
\label{Eq1}
\end{equation}

\begin{equation}
f({\bf U}_i, {\bf U}_j) = e^{\theta({\bf U}_i)^T\phi({\bf U}_j)}.
\label{Eq2}
\end{equation}

\begin{equation}
{\bf V} = {\tt softmax}\left({\bf U}^TW_{\theta}^TW_{\phi}{\bf U}\right)g({\bf U}). \label{eq:nl_Y}
\end{equation}

\begin{equation}
%{\bf \tilde{X}}_i = W_{z}{\bf Y}_i+ {\bf X}_i, \label{eq:nl_Z}
{\bf \widetilde{U}} = W_{z}{\bf V}+ {\bf U}, \label{eq:nl_Z}
\end{equation}

%\begin{figure}[htbp]
%\begin{minipage}[t]{0.5\textwidth}
%\centering
%\includegraphics[width=0.9\textwidth]{./pictures/non_local.pdf}
%\caption{全局注意力模块}
%\label{lab:1}
%\end{minipage}%
%\begin{minipage}[t]{0.5\textwidth}
%\centering
%\includegraphics[width=0.9\textwidth]{./pictures/non_local.pdf}
%\caption{全局注意力模块}
%\label{lab:2}
%\end{minipage}
%\end{figure}

结合以上模块，最终形成基于非局部注意力优化的图像压缩算法（NLAIC）。图\ref{fig:framework}为NLAIC的整体结构图。
\begin{figure*}[t]
   \centering
   %\includegraphics[scale=0.29]{./Fig/framework.pdf}
   %\caption{Proposed NLAIC framework using a variational autoencoder structure with embedded non-local attention optimization in the main and hyperprior encoders and decoders. }
   \subcaptionbox{\label{fig:framework}}{\includegraphics[scale=0.47]{./figs/framework-full.pdf}}
   \subcaptionbox{\label{sfig:non_local_attention}}{\includegraphics[scale=0.24]{./figs/non_local_attention.pdf}}\hspace{20mm}
   \subcaptionbox{\label{sfig:non_local_fig}}{\includegraphics[scale=0.28]{./figs/non_local.pdf}}
   \caption{{\bf 基于非局部注意力机制和3D上下文模型的图像压缩算法 - NLAIC.} (a) {\it NLAIC}:  一个在主编解码器和超先验编解码器中（包括$\mathbb{E}_m$, $\mathbb{E}_h$, $\mathbb{D}_m$ 和 $\mathbb{D}_h$）集成了非局部注意力优化的变分自编码器（VAE）. 图中卷积层的表示方式，以``Conv 5$\times$5$\times$192 s2"为例，其表示为一个卷积核大小为5$\times$5，卷积步长为2且有192个输出通道的卷积层（在解码器 $\mathbb{D}_m$ 和 $\mathbb{D}_h$中， ``Conv" 表示的是转置卷积）. NLAM表示非局部注意力模块.  ``Q''表示量化，``AE''和``AD''分别是算术编码和解码，$\mathbb{P}$表示基于3D卷积的算术编码概率模型, 上下文模型中的$k1$表示大小为1$\times$1$\times$1的3d卷积核; (b) {\it NLAM}: 主分支中包含了三个ResBlock. 掩膜分支结合非局部网络和ResBlock以生成注意力掩膜。\textcolor{red}{The details of ResBlock are shown in the dash frame.} (c) {\it 非局部网络 (NLN)}: $H\times{W}\times{C}$ 表示特征图的长为$H$，宽为$W$，通道数为$C$. $\oplus$表示加法操作而 $\otimes$表示矩阵乘法. }
\end{figure*}

\subsection{基于3D卷积的上下文模型}

\section{可变码率的学习压缩}
\subsection{JPEG中的可变码率技术}
传统的图像压缩算法如JPEG~\cite{Acharya2005JPEG}、H.264/AVC 以及HEVC~\cite{Sullivan2013Overview} intra profiles apply 预测、变换和量化系数QP（Quantization Parameters）consecutively. 以JPEG为例，JPEG采用离散余弦变换DCT（Discrete Cosine Transform）directly to the original image $X$ for transformed coefficients $G = {\sf DCT}(X)$, then applies a quantization matrix $Q$  for quantized data $B$, i.e.,
\begin{equation}
B(i,j) = {\sf ROUND}\left(\frac{{\sf DCT}(X)(i,j)}{Q(i,j)}\right), 0\leq i,j\leq7.
\end{equation}

其中，$Q(i,j)$是频率相关的。高频部分会被更粗力度的量化，而低频信号则采用细粒度的量化。初始默认的$Q_d$由IJG (Independent JPEG Group)提供，然后通过$S$作为控制缩放的系数，获得最终的$Q$来调整码率$Q = \frac{50+S*Q_d}{100}$。这种缩放的机制为我们接下来要提出的质量缩放系数提供了灵感。

\subsection{基于缩放系数的可变码率的学习压缩}
前文中已经提到，码率-失真联合优化的过程可以表示为 $R + \lambda D$，其中 $\lambda$ 是一个用来控制码率和失真的超参数. 为了获得最优的RD（Rate-Distortion）性能，大多数基于学习的方法需要通过设置不同的$\lambda$，重复训练多个独立的模型来匹配不同的码率点, 这样的方法在时间和存储空间维度上来说都非常的低效。目前已经有一些早期的工作 [9, 10, 6, 11, 12] 试图避免为不同码率训练多个模型, 但是这些方法仍然存在复杂度较高或者需要设计特定网络结构的问题。
首先, 我们想了解一下不同码率下的模型参数之间具有怎样的区别和联系。为了直观的进行对比，我们将不同码率（0.18 bits per pixel (bpp), 0.39 bpp和0.67 bpp）、不同通道（第59、100 和165个通道）的特征图在图\ref{fig:visualize}中进行可视化。 一个有趣的发现是：同一通道、不同码率下的特征图除了整体幅值发生了变化外，其中的纹理和模式表现出非常相似的性质。这一发现引出一种合理的假设：同JPEG等传统压缩方法中码率调节的方法类似地，我们可以在不进行完整的重复训练的基础上，通过对由同一编码器输出的特征进行缩放来实现可变码率的输出。因此, 在这篇文章中, 我们提出在原始编解码器中嵌入一组质量调节系数SFs（quality scaling factors）以及他们对应的逆函数ISF（Inverse SF） 来达到可变码率的输出；与此同时，保持原网络模型的参数不变，以节省模型重复训练时间和多个模型的存储空间。其结构如图\ref{fig:qf}所示。
需要之一的是，对于不同的目标码率，需要分别训练对应的SF系数。
\begin{figure}[t]
   \centering
   \includegraphics[scale=0.6]{./figs/fmaps_vis.pdf}  
   \caption{不同码率不同通道下的特征图可视化}
   \label{fig:visualize}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[scale=1.0]{./figs/baseline_qf.pdf}
\caption{在自编码器中嵌入质量调节系数}
\label{fig:qf}
\end{figure}

对于任意输入图像$Y$, 由编码器$\bf E$ 生成中间层特征$X = {\bf E}(Y)$。其中特征向量$X$共有$n$个通道，缩放系数SFs $({\sf SF} \in \{a_0,b_0\},\{a_1,b_1\},...,\{a_n,b_n\})$ 对应特征向量中的每一个通道有一组值，用于将原始的$X$缩放和平移为一个量化后更紧致的表达$\hat{\sf B}$。
对于每一个通道$i$, 我们通过如下公式进行变换：
\begin{align}
  \hat{\bf B}_i  = {\sf Q}\{ {\bf X}^{new}_i\} & = {\sf Q}\{ {\sf SF}\{{\bf X_i}\}\} = {\sf Q}\{ a_i\cdot{\bf X}_i + b_i\}, \label{eq:sf}\\
  & \hat{\bf X}_i = {\sf ISF}\{\hat{\bf B}_i\} = \frac{\hat{\bf B}_i - b_i}{a_i}.
\end{align}
其中$\hat{\sf B}$是量化后待熵编码的码字。 $\hat X$由$\hat {\sf B}$经过逆变换得到，并作为解码器$\bf D$的输入以生成重建图像$\hat{Y}={\bf D}({\hat X})$。
量化操作{\sf Q}的量化步长保持为$1$，由四舍五入函数$\sf ROUND$实现。

为了能够尽可能的提升熵编码的性能，我们希望能够在对特征进行概率估计的时候尽可能地准确。而在前面的公式中，原始的$X$被公式\eqref{eq:sf}线性地映射为了$\hat{\sf B}$，这就导致原本$X$的概率分布${p_d}(\bf x)$也同样被缩放和偏移了。 因此，为了能够不对熵估计模块重新训练，在进行熵编码时，我们使用的是经过$\sf ISF$之后的$\hat{\bf X}$来建模概率， 并通过同步地调整量化步长来匹配编码$\hat{\bf B}$时的实际步长，具体公式如下：
\begin{align}
  p(\hat{\bf B}) = {\prod_i} ({p_d}({\bf B}) *\mathcal{U}(-\frac{1}{2},\frac{1}{2}))(\hat {\bf B}_i) \nonumber \\ \Rightarrow {\prod_i} ({p_d}({\bf x}) *\mathcal{U}(-\frac{1}{2a_i},\frac{1}{2a_i})) (\hat{\bf x}^{new}_i)
  \label{eq:estimator}
\end{align}

\begin{figure}[htb]
      \centering
      \subcaptionbox{PSNR}{\includegraphics[width=7cm]{./figs/psnr.pdf}\label{fig:psnr_fac}}
      \subcaptionbox{MS-SSIM}{\includegraphics[width=7cm]{./figs/msssim_full.pdf}\label{fig:msim_qf}}
      \caption{Averaged Performance on Kodak using RGB images. Our results with SF enabled are derived from a pre-trained high bitrate model with model parameters fixed.  A set of scaling factors are trained for different bitrate budgets.}
      \label{fig:performance}
\end{figure}

\section{基于定点化推理的高效神经图像解码}
\section{神经图像编码的鲁棒性分析}
随着神经图像编码技术的研究渡过了前期的摸索阶段，技术路线逐渐明确且性能持续提升。近一两年来, 国际标准组织 ISO/IEC JPEG (Joint Photographic Experts Group) 委员会对于目前基于学习的图像编码方案已经进行了充分的研究和讨论，并已经开始着手启动基于深度学习技术的下一代图像编码标准化征集工作。尽管目前NIC的性能已经非常优秀，但网络模型是否具有良好的鲁棒性和泛化性对于此类方法的走向能否走向实用化至关重要。 但目前已有的工作中还没有对这一方面进行足够深入的研究。

图\ref{fidelity}展示了NIC相比于传统方法可能存在的细节失真的问题。除此之外，在其他工作~\cite{kim2020}中也发现NIC在重复压缩场景下，可能会出现不稳定的情况。基于以上这些发现，可见现有NIC算法的鲁棒性和稳定性确实是存在隐患的。因此迫切需要对其进行系统地研究并探索提升鲁棒性的方法。但此类不稳定的情况并不会总是发生，大大增加了人工寻找出大量有效样本的成本和难度。

\begin{figure}[t]
\centering
\includegraphics[scale=0.5]{./figs/fidelity.pdf}
\caption{传统方法JPEG与基于学习的压缩方法~\cite{xxx}重建图像的细节fidelity对比展示.
选取原始图片中用红框标出的同一位置区域进行对比 ({\it 见上方大图}). (a) 未压缩局部， (b) 经JPEG压缩后重建图像局部(\url{http://libjpeg.sourceforge.net/}), (c-e) 分别是针对MSE (Mean Squared Error), MS-SSIM~\cite{MS-SSIM}和LPIPS~\cite{zhang2018unreasonable}优化的NIC方法压缩后重建图像局部。公平起见，所有方法都将图片压缩到接近的PSNR水平（约24dB）。}
\label{fidelity}
\end{figure}

近些年来，对抗攻击已经被广泛地应用于深度神经网络的鲁棒性研究，包括图像分类~\cite{43405,nguyen2015deep}、语义分割~\cite{Xiao_2018_ECCV} 和目标检测~\cite{ijcai2019-134}等高级视觉任务，以及超分辨率~\cite{yin2018sr} 和光流生成~\cite{ranjan2019attacking}等低级视觉任务。受此启发，本文提出一种基于对抗样本攻击的方法，来高效大量地生成可以使网络不鲁棒的样本。共定义了有目标（Targeted）攻击和无目标（Untargeted）攻击两种攻击方式。其中有目标攻击的基本形式如下：
\begin{align}
\mathop{\arg\!\min}_{{\bf x}^{\ast}} {d}\{{\bf x},{\bf x}^{\ast}\} \ \text{s.t.} \ f({\bf x}^{\ast}) = y^t. \label{eq:targeted_attack}
\end{align}
其中$\bf x$为原始输入，${\bf x}^{\ast}$为加入特定噪声的对抗样本。分类网络为$f()$。$f({\bf x}) = y$. 而$y^t$为某个不同于原始标签$y$的目标标签。由此可见，有目标攻击期望在加入有限输入噪声的情况下，使网络输出为预先设定好的某个错误的结果。

而无目标攻击与有目标攻击的主要区别即在于，不再设定特定的$y^t$而只要求攻击之后网络输出错误的结果，公式如下：
\begin{align}
\mathop{\arg\!\min}_{{\bf x}^{\ast}} {d}\{{\bf x},{\bf x}^{\ast}\}  \ \text{s.t.} \ f({\bf x}^{\ast}) \neq f({\bf x}). \label{eq:untargeted_attack}
\end{align}

\subsection{图像压缩中的有目标攻击}
在对抗攻击这一研究领域，特别是对于很多诸如图像分类之类的计算机视觉任务，带有特定目标标签的有目标攻击是一种十分常见的形式。 有目标的图像压缩攻击也与之类似。对抗样本$x^*=x+\mathbf{n}$由原始图像中加入一定的噪声获得，其经过压缩后的重建图像表示为$\hat{x}^* = \mathbf{D_{\phi}}(\mathbf{E_{\theta}}(x^*))$；$x^t$和$\hat{x}^t$分别是原始目标图片以及其压缩后的重建图片。其中网络模型的参数$\mathbf{D_{\phi}}$和$\mathbf{E_{\theta}}$在整个攻击过程中是保持不变的。 最终，对抗样本生成的优化问题可以形式化为以下公式~\eqref{eq:tloss}, 以在控制输入噪声的同时，最小化输出与目标图片输出的距离. 
\begin{align}
    \mathop{\arg\min}_{\mathbf{n}}{L_{t}} =\left\{ \begin{array}{lc}
        ||\mathbf{n}||_2^2, & ||\mathbf{n}||_2^2 \geq \epsilon \\
        ||\hat{x}^{*}-\hat{x}^{t}||_2^2, & ||\mathbf{n}||_2^2 < \epsilon
    \end{array}
    \right.
    \label{eq:tloss}
\end{align}
\subsection{图像压缩中的无目标攻击}
相比于有目标攻击，在进行无目标攻击时不需要有特定的目标图片。对于图像压缩任务而言，我们设定的攻击目标此时变为最大化输出与输入的差异，其可以表示为~\eqref{eq:dloss}：
\begin{align}
    \mathop{\arg\min}_{\mathbf{n}}{L_{d}} =\left\{ \begin{array}{lc}
        ||\mathbf{n}||_2^2, & ||\mathbf{n}||_2^2 \geq \epsilon \\
        ||\hat{x}^{*}-\hat{x}^{t}||_2^2, & ||\mathbf{n}||_2^2 < \epsilon
    \end{array}
    \right.
    \label{eq:dloss}
\end{align}
\chapter{实验与分析}








\chapter{总结与展望}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 致谢，应放在《结论》之后
\begin{acknowledgement}
%thanks
时光荏苒，在南京大学的学习生活邻近结束，十一年光阴转瞬即逝，其间经历必将成为我人生宝贵的财富。在此文末，谨向数年来帮助我的老师和同学表达最衷心的感谢。

\end{acknowledgement}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




% 参考文献。应放在\backmatter之前。
% 推荐使用BibTeX，若不使用BibTeX时注释掉下面一句。
%\nocite{*}
\bibliography{phd-thesis-CT}


% 附录，必须放在参考文献后，backmatter前
\appendix
\chapter{源代码}\label{app:1}
\section{函数mptcp\_v4\_subflows()}
\begin{lstlisting}[language=C]
static void mptcp_v4_subflows(struct sock *meta_sk, const struct mptcp_loc4 *loc, struct mptcp_rem4 *rem)
{
   int i;
   int num;
   printk(KERN_INFO "******** Entering mptcp_v4_subflows ********\n");
  
   initial_my_global_var();
   switch(my_counter)
   {   
		case 1 : num = Fir; break;
		case 2 : num = Sec; break;
		case 3 : num = Thi; break;
		default : num = Fir;
	}

	for (i = 1; i < num; i++) 
	{
		printk(KERN_INFO "******** in mptcp_v4_subflows i = %d num = %d********\n",i,num);
		mptcp_init4_subsockets(meta_sk, loc, rem);
	}
	printk(KERN_INFO "******** Leaving mptcp_v4_subflows ********\n");
}
\end{lstlisting} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 书籍附件
\backmatter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成《学位论文出版授权书》页面，应放在最后一页
%\makelicense

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
